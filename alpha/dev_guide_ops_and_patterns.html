<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>oneDNN Graph: Operators and Fusion Patterns</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div class="mobile-nav"><i id="nav-btn"></i><a href="index.html">oneAPI Deep Neural Network Library Graph API (oneDNN Graph)</a></div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">
     <a href="index.html">
      <div id="full-name">oneAPI Deep Neural Network Library Graph API (oneDNN Graph)</div>
    </a>
   </div>
   <div id="projectbrief">Performance Library for DNN Graph Optimization</div>
   <div id="projectnumber">0.5.2</div>
  <div>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('dev_guide_ops_and_patterns.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Operators and Fusion Patterns </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_doc_programming_model_ops_and_patterns"></a> </p>
<h1><a class="anchor" id="autotoc_md29"></a>
Operators</h1>
<p>Supported operation refers to operation which can be converted to oneDNN Graph OP and thus can be part of oneDNN Graph partition. The alpha release supports the following operations as part of Opset defined in oneDNN Graph Spec. It supports FP32/FP16/BF16/S8/U8 data type. For complete OP definition, please refer to <a href="https://spec.oneapi.com/onednn-graph/latest/ops/index.html">oneDNN Graph Specification</a>.</p>
<ul>
<li>Abs</li>
<li>Add</li>
<li>AvgPool</li>
<li>AvgPoolBackprop</li>
<li>BatchNormForwardTraining</li>
<li>BatchNormInference</li>
<li>BatchNormTrainingBackprop</li>
<li>BiasAdd</li>
<li>BiasAddBackprop</li>
<li>Clamp</li>
<li>ClampBackprop</li>
<li>Concat</li>
<li>Convolution</li>
<li>ConvolutionBackpropData</li>
<li>ConvolutionBackpropFilters</li>
<li>ConvTranspose</li>
<li>ConvTransposeBackpropData</li>
<li>ConvTransposeBackpropFilters</li>
<li>Dequantize</li>
<li>DynamicDequantize</li>
<li>DynamicQuantize</li>
<li>DynamicReshape</li>
<li>DynamicTranspose</li>
<li>Divide</li>
<li>Elu</li>
<li>EluBackprop</li>
<li>End</li>
<li>Erf</li>
<li>Exp</li>
<li>GELU</li>
<li>GELUBackprop</li>
<li>HardTanh</li>
<li>HardTanhBackprop</li>
<li>HardSwish</li>
<li>HardSwishBackprop</li>
<li>Index</li>
<li>Interpolate</li>
<li>InterpolateBackprop</li>
<li>LayerNorm</li>
<li>LayerNormBackprop</li>
<li>Log</li>
<li>LogSoftmax</li>
<li>LogSoftmaxBackprop</li>
<li>MatMul</li>
<li>MaxPool</li>
<li>MaxPoolBackprop</li>
<li>Maximum</li>
<li>Minimum</li>
<li>Multiply</li>
<li>Negative</li>
<li>Pow</li>
<li>PowBackprop</li>
<li>PowBackpropExponent</li>
<li>PReLU</li>
<li>PReLUBackprop</li>
<li>Quantize</li>
<li>Reciprocal</li>
<li>ReduceL1</li>
<li>ReduceL2</li>
<li>ReduceMax</li>
<li>ReduceMean</li>
<li>ReduceMin</li>
<li>ReduceProd</li>
<li>ReduceSum</li>
<li>ReLU</li>
<li>ReLUBackprop</li>
<li>Reorder</li>
<li>Round</li>
<li>Sigmoid</li>
<li>SigmoidBackprop</li>
<li>Sign</li>
<li>SoftMax</li>
<li>SoftMaxBackprop</li>
<li>SoftPlus</li>
<li>SoftPlusBackprop</li>
<li>Sqrt</li>
<li>SqrtBackprop</li>
<li>StaticReshape</li>
<li>StaticTranspose</li>
<li>Square</li>
<li>SquaredDifference</li>
<li>Subtract</li>
<li>Tanh</li>
<li>TanhBackprop</li>
<li>TypeCast</li>
<li>Wildcard</li>
</ul>
<h1><a class="anchor" id="autotoc_md30"></a>
Fusion Patterns</h1>
<h2><a class="anchor" id="autotoc_md31"></a>
1. Describing fusion pattern</h2>
<p>Fusion pattern describes a graph partition which oneDNN Graph takes as input and generates optimized code. The pattern is described using oneDNN Graph OP names with the following convention.</p>
<p><code>"+"</code> describes a chain of two OPs. The preceeding OP produces an output tensor, which is consumed by the following OP as its first operand.</p>
<p><code>"[]"</code> describes a component of the overall pattern description. For example, it could include a subgraph or all the OP choices within the bracket.</p>
<p><code>"|"</code> describes choices of multiple operations, say A+[B|C] means the graph partition contains A followed by B or C.</p>
<p><code>","</code> describes a graph composed of multiple subgraphs, each subgraph marks its output tensor explicitly, which is consumed by other subgraphs.</p>
<p><code>Superscript</code> denotes the numbers of repetition pattern. For example, A+[B|C]<sup>3</sup> means the graph partition contains A followed by 3 OPs, each of them is either B or C. The superscript could be a range of number meaning allowing a range of repetition. If the range is between 0 and 1, we use superscript <code>"?"</code>.</p>
<p><code>Subscript</code> denotes the input and output tensors which need to explicitly mark the producer and consumer relation within one graph partition. For example, A<sub>&gt;t1</sub>+B+C<sub>&lt;t1</sub> refers to the pattern started with A followed by B and C, and C takes an implicit input tensor from B and an extra tensor t1 output from A. <code>"&gt;"</code> refers to the output tensor, and <code>"&lt;"</code> for input tensor. Input and output tensor between neighbor ops are not explicitly marked, for example, B consumes t1 implicitly in the example above.</p>
<p>Subscript <code>"out"</code> marks the output tensor of a certain OP to be the output of a graph partition. For example, in A<sub>&gt;t1</sub>+B<sub>&gt;out</sub>+C<sub>&lt;t1,&gt;out</sub> B’s output and C’s output are marked as output tensors.</p>
<p>Subscript <code>"in"</code> marks the input tensor of a certain OP to be the input of a graph partition. For example, in A<sub>&lt;in1</sub>+B<sub>&lt;in1</sub> A’s input and B's second input are graph partition input, and they share the same input tensor in1. Most input tensors of a graph partition are not explicitly marked. For example, the input tensors of the first OP are implicitly regarded as graph partition inputs. Besides, for input tensors of other OPs, if they are not produced by any proceeding OPs, they are regarded as implicit graph partition inputs. In the example A<sub>&gt;t1</sub>+B+C<sub>&lt;t1</sub>, A’s inputs are regarded as implicit graph partition inputs, and if B is a binary operation, the second input tensor is an implicit graph partition input.</p>
<h2><a class="anchor" id="autotoc_md32"></a>
2. Post-ops fusion pattern</h2>
<p>The following categories will be used in describing post-ops fusion pattern.</p>
<p>Unary = [Abs | Clamp | Elu | Exp | GELU | HardTanh | HardSwish | LeakyReLU | Log | Sigmoid | SoftPlus | Pow | ReLU | Round | Sqrt | Square | Tanh]</p>
<p>Binary = [Add | Divide | Maximum | Minimum | Multiply | Subtract]</p>
<p>Reduction = [ReduceL1 | ReduceL2 | ReduceMax | ReduceMean | ReduceMin | ReduceProd | ReduceSum]</p>
<h3><a class="anchor" id="autotoc_md33"></a>
2.1 Inference</h3>
<h4><a class="anchor" id="autotoc_md34"></a>
2.1.1 Floating Point Patterns</h4>
<ul>
<li>Convolution Post-ops<ul>
<li>Pattern: Convolution + BiasAdd<sup>?</sup> + BatchNormInference<sup>?</sup> + [Unary | Binary]<sup>0-3</sup><sub>&gt;out</sub></li>
<li>Description: this pattern is widely used in Convolution Neural Networks, i.e. ResNet, ResNext, SSD, etc.</li>
</ul>
</li>
<li>ConvTranspose Post-ops<ul>
<li>Pattern: ConvTranspose + BiasAdd<sup>?</sup> + [Unary | Binary]<sup>?</sup><sub>&gt;out</sub></li>
<li>Description: this pattern is widely used in Generative Adversarial Networks.</li>
</ul>
</li>
<li>Interpolate Post-ops<ul>
<li>Pattern: Interpolate + [Unary | Binary]<sup>?</sup><sub>&gt;out</sub></li>
<li>Description: this pattern is widely used for image processing.</li>
</ul>
</li>
<li>MatMul Post-ops<ul>
<li>Pattern: MatMul + BiasAdd<sup>?</sup> + [Unary | Binary]<sup>0-3</sup><sub>&gt;out</sub></li>
<li>Description: this pattern is widely used in language models and recommendation models, i.e. BERT, DLRM, etc.</li>
</ul>
</li>
<li>Reduction Post-ops<ul>
<li>Pattern: Reduction + [Unary | Binary]<sup>?</sup><sub>&gt;out</sub></li>
<li>Description: this pattern is widely used for data processing, i.e. loss reduction.</li>
</ul>
</li>
<li>Unary Post-ops<ul>
<li>Pattern: Unary + Binary<sup>?</sup><sub>&gt;out</sub></li>
<li>Description: this pattern is widely used in Convolution Neural Networks.</li>
</ul>
</li>
<li>Binary Post-ops<ul>
<li>Pattern: Binary + [Unary | Binary]<sup>?</sup><sub>&gt;out</sub></li>
<li>Description: this pattern is widely used in Generative Adversarial Networks, i.e. ParallelWaveGAN.</li>
</ul>
</li>
<li>Pooling Post-ops<ul>
<li>Pattern: [AvgPool | MaxPool] + Binary<sup>?</sup><sub>&gt;out</sub></li>
<li>Description: this pattern is widely used in Convolution Neurual Networks.</li>
</ul>
</li>
<li>Batch Normalization Post-ops<ul>
<li>Pattern: BatchNormInference + ReLU<sub>&gt;out</sub></li>
<li>Description: this pattern is widely used in Convolution Neurual Networks, i.e. DenseNet.</li>
</ul>
</li>
<li>Misc Post-ops<ul>
<li>Pattern: Reciprocal + Multiply<sub>&gt;out</sub></li>
<li>Pattern: Reorder + Add<sub>&gt;out</sub></li>
</ul>
</li>
</ul>
<h4><a class="anchor" id="autotoc_md35"></a>
2.1.2 Quantized Patterns</h4>
<ul>
<li>Quantized Convolution Post-ops<ul>
<li>Pattern: Quantize<sup>?</sup> + Dequantize<sub>&gt;t1</sub>, Dequantize<sub>&gt;t2</sub><sup>?</sup>, Dequantize + Convolution<sub>&lt;t1</sub> + BiasAdd<sup>?</sup> + [Unary<sup>0-3</sup> | Add<sub>&lt;t2</sub><sup>?</sup>] + Quantize<sup>?</sup><sub>&gt;out</sub></li>
</ul>
</li>
<li>Quantized ConvTranspose Post-ops<ul>
<li>Pattern: Quantize<sup>?</sup> + Dequantize<sub>&gt;t1</sub>, Dequantize<sub>&gt;t2</sub><sup>?</sup>, Dequantize + ConvTranspose<sub>&lt;t1</sub> + BiasAdd<sup>?</sup> + [Unary<sup>0-3</sup> | Add<sub>&lt;t2</sub><sup>?</sup>] + Quantize<sup>?</sup><sub>&gt;out</sub></li>
</ul>
</li>
<li>Quantized MatMul Post-ops<ul>
<li>Pattern: Quantize<sup>?</sup> + Dequantize<sub>&gt;t1</sub>, Dequantize<sub>&gt;t2</sub><sup>?</sup>, Dequantize + MatMul<sub>&lt;t1</sub> + BiasAdd<sup>?</sup> + [Unary<sup>0-3</sup> | Add<sub>&lt;t2</sub><sup>?</sup>] + Quantize<sup>?</sup><sub>&gt;out</sub></li>
</ul>
</li>
<li>Quantized Unary Post-ops<ul>
<li>Pattern: Dequantize + ReLU + Quantize<sub>&gt;out</sub></li>
</ul>
</li>
<li>Quantized Pooling Post-ops<ul>
<li>Pattern: Dequantize + [AvgPool | MaxPool] + Quantize<sub>&gt;out</sub></li>
<li>Pattern: Dequantize<sub>&gt;t1</sub>, Dequantize + [AvgPool | MaxPool] + Add<sub>&lt;t1</sub> + Quantize<sub>&gt;out</sub></li>
</ul>
</li>
<li>Misc Quantized Post-ops<ul>
<li>Pattern: Dequantize + Reorder + Quantize<sub>&gt;out</sub></li>
<li>Pattern: Dequantize<sub>&gt;t1</sub>, Dequantize + Reorder + Add<sub>&lt;t1</sub> + Quantize<sub>&gt;out</sub></li>
</ul>
</li>
</ul>
<h3><a class="anchor" id="autotoc_md36"></a>
2.2 Training</h3>
<ul>
<li>ConvolutionBackpropFilters Post-ops<ul>
<li>Pattern: ConvolutionBackpropFilters + BiasAddBackprop<sub>&gt;out</sub></li>
</ul>
</li>
<li>Misc Post-ops<ul>
<li>Pattern: ReLUBackprop + BatchNormTrainingBackprop<sub>&gt;out</sub></li>
</ul>
</li>
</ul>
<p>All the post-ops fusion patterns are supported by default.</p>
<h2><a class="anchor" id="autotoc_md37"></a>
3. Aggressive fusion pattern</h2>
<p>The following category will be used to describe aggressive fusion pattern.</p>
<ul>
<li>Activation = [ReLU | Sigmoid | GELU]</li>
<li>ActivationBackprop = [ReLUBackprop | SigmoidBackprop | GELUBackprop]</li>
</ul>
<h3><a class="anchor" id="autotoc_md38"></a>
3.1 Inference</h3>
<h4><a class="anchor" id="autotoc_md39"></a>
3.1.1 Floating Point Patterns</h4>
<ul>
<li>MHA (Multi-head Attention)<ul>
<li><p class="startli">Pattern: MatMul + [Multiply | Divide] + Add + Softmax + MatMul + StaticTranspose + Reorder<sub>&gt;out</sub></p>
<p class="startli"><img src="../images/oneDNN_graph_MHA_fp32_patterns.png" alt="MHA Floating Point Patterns" width="30%" height="30%" class="inline"/></p>
</li>
<li>Description: the pattern is used in various BERT models. The <code>Reorder</code> op in the pattern could change the physical layout of the input tensor. It could be translated from <code>torch.contiguous</code>.</li>
</ul>
</li>
<li>MLP (Multi-layer Perceptron)<ul>
<li>Pattern: MatMul + Activation<sub>&gt;t1</sub>, [MatMul<sub>&lt;t1</sub> + Activation<sub>&gt;t1</sub>]<sup>0-4</sup>, MatMul<sub>&lt;t1</sub> + Activation<sub>&gt;out</sub></li>
<li>Description: this pattern is composed of multiple layers of MatMul + post-ops. It is used in recommendation model, e.g. DLRM.</li>
</ul>
</li>
</ul>
<h4><a class="anchor" id="autotoc_md40"></a>
3.1.2 Quantized Patterns</h4>
<ul>
<li>Quantized MHA<ul>
<li><p class="startli">Pattern: Dequantize<sub>&gt;t1</sub>, Dequantize<sub>&gt;t2</sub>, Dequantize + MatMul<sub>&lt;t1</sub> + [Multiply | Divide] + Add + Softmax + Quantize + Dequantize + MatMul<sub>&lt;t2</sub> + StaticTranspose + Reorder + Quantize<sub>&gt;out</sub></p>
<p class="startli"><img src="../images/oneDNN_graph_MHA_quantized_patterns.png" alt="MHA Quantized Patterns" width="45%" height="45%" class="inline"/></p>
</li>
<li>Descriptions: this pattern is used in quantized BERT models. The <code>Reorder</code> op could change the physical layout of the input tensor. It could be translated from <code>torch.contiguous</code>.</li>
</ul>
</li>
<li>Quantized MLP<ul>
<li><p class="startli">Pattern:</p>
<p class="startli">Dequantize<sub>&gt;t1</sub>, Dequantize + MatMul<sub>&lt;t1</sub> + Activation + Quantize<sub>&gt;t2</sub>,</p>
<p class="startli">[Dequantize<sub>&gt;t3</sub>, Dequantize<sub>&lt;t2</sub> + MatMul<sub>&lt;t3</sub> + Activation + Quantize<sub>&gt;t2</sub>]<sup>0-4</sup>,</p>
<p class="startli">Dequantize<sub>&gt;t4</sub>, Dequantize<sub>&lt;t2</sub> + MatMul<sub>&lt;t4</sub> + Activation + Quantize<sub>&gt;out</sub></p>
</li>
<li>Description: this pattern is used in quantized recommendation models, e.g. int8 DLRM.</li>
</ul>
</li>
</ul>
<h3><a class="anchor" id="autotoc_md41"></a>
3.2 Training</h3>
<ul>
<li>MHA<ul>
<li>Forward Pattern: MatMul + [Multiply | Divide] + Add + Softmax <sub>&gt;out1</sub> + Multiply<sub>&gt;out2</sub> + MatMul + StaticTranspose + StaticReshape<sub>&gt;out3</sub></li>
<li><p class="startli">Backward Pattern: StaticReshape + StaticTranspose<sub>&gt;t1</sub> + MatMul + Multiply<sub>&gt;t2</sub> + Subtract<sub>&lt;t3</sub> + Multiply + [Multiply | Divide]<sub>&gt;t4</sub> + MatMul<sub>&gt;out1</sub>, Multiply<sub>&lt;t2</sub> + ReduceSum<sub>&gt;t3</sub>, MatMul<sub>&lt;t1,&gt;out2</sub>, MatMul<sub>&lt;t4,&gt;out3</sub></p>
<p class="startli"><img src="../images/oneDNN_graph_MHA_training_patterns.png" alt="MHA Training Patterns" class="inline"/></p>
</li>
<li>Description: this pattern is used in BERT training cases. The pattern is similar to MHA inference, except for an extra Multiply op after Softmax.</li>
</ul>
</li>
<li>MLP<ul>
<li>Forward Pattern: MatMul<sub>&gt;out1</sub> + Activation<sub>&gt;t1,&gt;out2</sub>, [MatMul<sub>&lt;t1,&gt;out3</sub> + Activation<sub>&gt;t1,&gt;out4</sub>]<sup>0-4</sup>, MatMul<sub>&lt;t1,&gt;out5</sub> + Activation<sub>&gt;out6</sub></li>
<li><p class="startli">Backward Pattern:</p>
<p class="startli">StaticTranspose<sup>?</sup><sub>&gt;t0</sub>, ActivationBackprop<sub>&gt;t2</sub> + MatMul<sub>&lt;t0,&gt;t1</sub>, ReduceSum<sup>?</sup><sub>&lt;t2,&gt;out1</sub>, StaticTranspose<sup>?</sup> + MatMul<sub>&lt;t2,&gt;out2</sub>,</p>
<p class="startli">[StaticTranspose<sup>?</sup><sub>&gt;t3</sub>, ActivationBackprop<sub>&gt;t4,&lt;t1</sub> + MatMul<sub>&lt;t3,&gt;t1</sub>, ReduceSum<sup>?</sup><sub>&lt;t4,&gt;out3</sub>, StaticTranspose<sup>?</sup> + MatMul<sub>&lt;t4,&gt;out4</sub>]<sup>0-4</sup>,</p>
<p class="startli">StaticTranspose<sup>?</sup><sub>&gt;t5</sub>, ActivationBackprop<sub>&gt;t6,&lt;t1</sub> + MatMul<sub>&lt;t5,&gt;out5</sub>, ReduceSum<sup>?</sup><sub>&lt;t6,&gt;out6</sub>, StaticTranspose<sup>?</sup> + MatMul<sub>&lt;t6,&gt;out7</sub></p>
<p class="startli"><img src="../images/oneDNN_graph_MLP_training_patterns.png" alt="MLP Training Patterns" class="inline"/></p>
<p class="startli">MLP Training Patterns: MLP Forward Pattern (left); MLP Backward Pattern (right). Solid orange lines denote the connection between successive repetition layers. Inputs/outputs denoted with black solid lines are required in each layer of repetition. Inputs denoted with blue solid lines are required only in the first repetition layer, and outputs in blue exist only in the last repetition layer.</p>
</li>
<li>Description: this pattern is used in recommendation models, e.g. DLRM.</li>
</ul>
</li>
</ul>
<p>Aggressive patterns are supported by <a href="https://github.com/oneapi-src/oneDNN/tree/dev-graph/doc#onednn-graph-compiler">oneDNN Graph Compiler</a>. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<div class="footer">
    <script>
        $('#top').prependTo($('#side-nav'));
    </script>
    <div class="footer-wrapper">
        <hr>
        <ul class="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>