<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>oneDNN Graph: Getting started on both CPU and GPU with SYCL extensions API</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div class="mobile-nav"><i id="nav-btn"></i><a href="index.html">oneAPI Deep Neural Network Library Graph API (oneDNN Graph)</a></div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">
     <a href="index.html">
      <div id="full-name">oneAPI Deep Neural Network Library Graph API (oneDNN Graph)</div>
    </a>
   </div>
   <div id="projectbrief">Performance Library for DNN Graph Optimization</div>
   <div id="projectnumber">0.4.3</div>
  <div>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('dev_guide_sycl_programming.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Getting started on both CPU and GPU with SYCL extensions API </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_doc_programming_model_sycl_get_started"></a> </p><dl class="section warning"><dt>Warning</dt><dd>This tutorial is deprecated due to the programming model changes and will be removed soon, please refer to <a href="../../tests/demo/src/sycl_simple_pattern.cpp">sycl_simple_pattern.cpp</a> for latest version.</dd></dl>
<p>This is an example to demonstrate how to build a simple graph and run on CPU/GPU with SYCL extension APIs.</p>
<p>In this example, you will learn the below things about oneDNN Graph.</p>
<ul>
<li>How to build a graph and get several partitions</li>
<li>How to create engine, allocator and stream</li>
<li>How to compile a partition</li>
<li>How to execute a compiled partition with input tensors on a specific stream</li>
</ul>
<p><b>Note</b>: currently, oneDNN Graph has limited support for direct programming model. For example, users need to know how many inputs/outputs of a self-defined pattern or partition.</p>
<p>The full example code can be found at <a href="../../examples/cpp/sycl_get_started.cpp">sycl_get_started.cpp</a>.</p>
<h1><a class="anchor" id="autotoc_md32"></a>
Public headers</h1>
<p>To start using oneDNN Graph, users should include the <a href="../../include/oneapi/dnnl/dnnl_graph.hpp">dnnl_graph.hpp</a> header file in the application. If a user wants to run on a SYCL device like this example, he/she also need include <a href="../../include/oneapi/dnnl/dnnl_graph_sycl.hpp">dnnl_graph_sycl.hpp</a>. All the C++ APIs reside in namespace <code>dnnl::graph</code>.</p>
<div class="fragment"><div class="line"><span class="preprocessor">#include &quot;oneapi/dnnl/dnnl_graph.hpp&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;oneapi/dnnl/dnnl_graph_sycl.hpp&quot;</span></div>
<div class="line"><span class="keyword">using namespace </span>dnnl::graph;</div>
<div class="line"><span class="keyword">using namespace </span>cl::sycl; <span class="comment">// for SYCL related APIs</span></div>
</div><!-- fragment --><h1><a class="anchor" id="autotoc_md33"></a>
sycl_get_started_tutorial() function</h1>
<h2><a class="anchor" id="autotoc_md34"></a>
Build graph and get partitions</h2>
<p>In this section, firstly we will build a graph containing the pattern like <code>conv0-&gt;relu0-&gt;conv1-&gt;relu1</code>. After that, we can get all of partitions which are determined by backend.</p>
<p>To create a graph, <a href="../../include/oneapi/dnnl/dnnl_graph.hpp#L102"><code>dnnl::graph::engine::kind</code></a> is needed because the returned partitions may vary on different devices.</p>
<div class="fragment"><div class="line">graph g(engine_kind);</div>
</div><!-- fragment --><p>To build a graph, the connection relationship of different ops must be known. In oneDNN Graph, the <code>id</code> of <a href="../../include/oneapi/dnnl/dnnl_graph.hpp#L290"><code>dnnl::graph::logical_tensor</code></a> is used to express such relationship. Besides that, a logical tensor describes the metadata of a tensor, like element data type, number of dimensions, size for each dimension (shape), layout, and the total size of the data.</p>
<p>So for the first <code>Convolution</code> operator, input and output logical tensors are created as below. At this stage, the information in a logical tensor maybe not complete. For example, <code>shape</code> or <code>layout</code> is still unknown at the early graph optimization pass.</p>
<div class="fragment"><div class="line">logical_tensor conv0_src_desc {logical_id[0], logical_tensor::data_type::f32, input_dims, logical_tensor::layout_type::undef};</div>
<div class="line">logical_tensor conv0_weight_desc {logical_id[1], logical_tensor::data_type::f32, weight_dims,logical_tensor::layout_type::undef};</div>
<div class="line">logical_tensor conv0_dst_desc {logical_id[2], logical_tensor::data_type::f32, dst_dims, logical_tensor::layout_type::undef};</div>
</div><!-- fragment --><p>Next step is to create a <code>Convolution</code> operator with all of input/output logical tensors and required attributes. For more details about these attributes, please find the definitions in our <a href="https://spec.oneapi.com/onednn-graph/latest/ops/convolution/Convolution_1.html">public specification</a>.</p>
<div class="fragment"><div class="line">op conv0(0, op::kind::Convolution, {conv0_src_desc, conv0_weight_desc}, {conv0_dst_desc}, <span class="stringliteral">&quot;conv0&quot;</span>);</div>
<div class="line">conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;strides&quot;</span>, {4, 4});</div>
<div class="line">conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;pads_begin&quot;</span>, {0, 0});</div>
<div class="line">conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;pads_end&quot;</span>, {0, 0});</div>
<div class="line">conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;dilations&quot;</span>, {1, 1});</div>
<div class="line">conv0.set_attr&lt;int64_t&gt;(<span class="stringliteral">&quot;groups&quot;</span>, 1);</div>
<div class="line">conv0.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;data_format&quot;</span>, <span class="stringliteral">&quot;NCX&quot;</span>);</div>
<div class="line">conv0.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;filter_format&quot;</span>, <span class="stringliteral">&quot;OIX&quot;</span>);</div>
</div><!-- fragment --><p>For the first <code>BiasAdd</code> and <code>ReLU</code> operators, one can use the similar way to create them.</p>
<div class="fragment"><div class="line">logical_tensor conv0_bias_desc {logical_id[3], logical_tensor::data_type::f32, bias_dims, logical_tensor::layout_type::undef};</div>
<div class="line">logical_tensor conv0_bias_add_dst_desc {logical_id[4], logical_tensor::data_type::f32, dst_dims, logical_tensor::layout_type::undef};</div>
<div class="line">op conv0_bias_add(1, op::kind::BiasAdd, {conv0_dst_desc, conv0_bias_desc}, {conv0_bias_add_dst_desc}, <span class="stringliteral">&quot;conv0_bias_add&quot;</span>);</div>
<div class="line">logical_tensor relu0_dst_desc {logical_id[5], logical_tensor::data_type::f32, dst_dims, logical_tensor::layout_type::undef};</div>
<div class="line">op relu0(2, op::kind::ReLU, {conv0_bias_add_dst_desc}, {relu0_dst_desc}, <span class="stringliteral">&quot;relu0&quot;</span>);</div>
</div><!-- fragment --><p>The creations of rest operators is as similar as above, please find the <a href="../../examples/cpp/sycl_get_started.cpp">example code</a> for details.</p>
<p>After all those operators are created, users can add these ops into the graph.</p>
<div class="fragment"><div class="line">g.add_op(conv0);</div>
<div class="line">g.add_op(relu0);</div>
<div class="line">g.add_op(conv1);</div>
<div class="line">g.add_op(relu1);</div>
<div class="line">g.add_op(conv0_bias_add);</div>
<div class="line">g.add_op(conv1_bias_add);</div>
</div><!-- fragment --><p>Then by calling <a href="../../include/oneapi/dnnl/dnnl_graph.hpp#L1284"><code>get_partitions()</code></a>, users can get several partitions. In this example, there should be two partitions: <code>conv0+relu0</code> and <code>conv1+relu1</code>.</p>
<p><b>Note</b>: setting env variable <code>DNNL_GRAPH_DUMP=1</code> can save internal graphs into dot files before/after graph fusion.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> partitions = g.get_partitions();</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md35"></a>
Compile partitions</h2>
<p>In the real world, frameworks will provide device info for oneDNN Graph. For example, they may provide a <code>sycl::queue</code> like below:</p>
<div class="fragment"><div class="line">sycl::queue q = (engine_kind == engine::kind::gpu) ? sycl::queue(gpu_selector {}) : sycl::queue(cpu_selector {});</div>
</div><!-- fragment --><p>Based on the above <code>sycl::queue</code>, users can create a <a href="../../include/oneapi/dnnl/dnnl_graph.hpp#L45">dnnl::graph::allocator</a> and <a href="../../include/oneapi/dnnl/dnnl_graph.hpp#L97">dnnl::graph::engine</a>. Here, <code>sycl_malloc_wrapper</code> and <code>sycl_free_wrapper</code> are call-back functions and also provided by frameworks.</p>
<p>In oneDNN Graph, SYCL extension APIs reside in the namespace <code><a class="el" href="namespacednnl_1_1graph_1_1sycl__interop.html" title="SYCL interoperability namespace.">dnnl::graph::sycl_interop</a></code>, which are defined at <a href="../../include/oneapi/dnnl/dnnl_graph_sycl.hpp">dnnl_graph_sycl.hpp</a>.</p>
<div class="fragment"><div class="line">engine eng = sycl_interop::make_engine(q.get_device(), q.get_context());</div>
<div class="line">allocator alloc = sycl_interop::make_allocator(sycl_malloc_wrapper, sycl_free_wrapper);</div>
<div class="line">eng.set_allocator(alloc);</div>
</div><!-- fragment --><p>At runtime, the information about a tensor should be known, including <code>shape</code> and <code>layout</code>. So here users need to create those input and output logical tensors again with concrete info.</p>
<div class="fragment"><div class="line">logical_tensor conv0_src_desc_plain {logical_id[0], logical_tensor::data_type::f32, input_dims, logical_tensor::layout_type::strided};</div>
<div class="line">logical_tensor conv0_weight_desc_plain {logical_id[1], logical_tensor::data_type::f32, weight_dims, logical_tensor::layout_type::strided};</div>
<div class="line">logical_tensor conv0_bias_desc_plain {logical_id[3], logical_tensor::data_type::f32, bias_dims, logical_tensor::layout_type::strided};</div>
<div class="line">logical_tensor relu0_dst_desc_plain {logical_id[5], logical_tensor::data_type::f32, dst_dims, logical_tensor::layout_type::strided};</div>
</div><!-- fragment --><p>Then compile the partition 0 to get compiled partition.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> cp0 = partitions[0].compile({conv0_src_desc_plain, conv0_weight_desc_plain, conv0_bias_desc_plain}, {relu0_dst_desc_plain}, eng);</div>
</div><!-- fragment --><p>In the same way, users can get the compiled partition from the partition 1.</p>
<div class="fragment"><div class="line">logical_tensor conv1_weight_desc_plain {logical_id[6], logical_tensor::data_type::f32, weight1_dims, logical_tensor::layout_type::strided};</div>
<div class="line">logical_tensor conv1_bias_desc_plain {logical_id[8], logical_tensor::data_type::f32, bias1_dims, logical_tensor::layout_type::strided};</div>
<div class="line">logical_tensor relu1_dst_desc_plain {logical_id[10], logical_tensor::data_type::f32, dst1_dims, logical_tensor::layout_type::strided};</div>
<div class="line"> </div>
<div class="line"><span class="keyword">auto</span> cp1 = partitions[1].compile({relu0_dst_desc_plain, conv1_weight_desc_plain, conv1_bias_desc_plain}, {relu1_dst_desc_plain}, eng);</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md36"></a>
Execute the compiled partitions</h2>
<p>In oneDNN Graph, a <a href="../../include/oneapi/dnnl/dnnl_graph.hpp#L239">dnnl::grap::stream</a> is the logical abstraction for execution units. It is created on top of oneDNN Graph engine. For SYCL device, it also contains an opencl queue.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> strm = sycl_interop::make_stream(eng, q);</div>
</div><!-- fragment --><p>Since this example is to show how to run on a SYCL device, users need to prepare SYCL memory buffer firstly. In the real world, these buffers are probably already prepared by frameworks. Here, we use <a href="https://docs.oneapi.com/versions/latest/dpcpp/iface/usm-malloc.html#sycl-malloc-shared"><code>malloc_shared</code></a> to request USM buffers which is an interface provided by DPCPP.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> conv0_src_data = (<span class="keywordtype">float</span> *)malloc_shared(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(product(input_dims)) * <span class="keyword">sizeof</span>(float), q.get_device(), q.get_context());</div>
<div class="line"><span class="keyword">auto</span> conv0_weight_data = (<span class="keywordtype">float</span> *)malloc_shared(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(product(weight_dims)) * <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>), q.get_device(), q.get_context());</div>
<div class="line"><span class="keyword">auto</span> conv0_bias_data = (<span class="keywordtype">float</span> *)malloc_shared(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(product(bias_dims)) * <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>), q.get_device(), q.get_context());</div>
<div class="line"><span class="keyword">auto</span> relu0_dst_data = (<span class="keywordtype">float</span> *)malloc_shared(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(product(dst_dims)) * <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>), q.get_device(), q.get_context());</div>
<div class="line"><span class="keyword">auto</span> conv1_weight_data = (<span class="keywordtype">float</span> *)malloc_shared(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(product(weight1_dims)) * <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>), q.get_device(), q.get_context());</div>
<div class="line"><span class="keyword">auto</span> conv1_bias_data = (<span class="keywordtype">float</span> *)malloc_shared(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(product(bias1_dims)) * <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>), q.get_device(), q.get_context());</div>
<div class="line"><span class="keyword">auto</span> relu1_dst_data = (<span class="keywordtype">float</span> *)malloc_shared(<span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(product(dst1_dims)) * <span class="keyword">sizeof</span>(<span class="keywordtype">float</span>), q.get_device(), q.get_context());</div>
</div><!-- fragment --><p>Before the execution, users also need to bind the logical tensor and memory buffer to <a href="../../include/oneapi/dnnl/dnnl_graph.hpp#L581">dnnl::graph::tensor</a>.</p>
<div class="fragment"><div class="line">tensor conv0_src(conv0_src_desc_plain, eng, conv0_src_data);</div>
<div class="line">tensor conv0_weight(conv0_weight_desc_plain, eng, conv0_weight_data);</div>
<div class="line">tensor conv0_bias(conv0_bias_desc_plain, eng, conv0_bias_data);</div>
<div class="line">tensor relu0_dst(relu0_dst_desc_plain, eng, relu0_dst_data);</div>
<div class="line">std::vector&lt;tensor&gt; out0_list = {relu0_dst};</div>
<div class="line"> </div>
<div class="line">sycl_interop::execute(cp0, strm, {conv0_src, conv0_weight, conv0_bias}, out0_list);</div>
</div><!-- fragment --><p>In the same way, users can execute the second compiled partition.</p>
<div class="fragment"><div class="line">tensor conv1_weight(conv1_weight_desc_plain, eng, conv1_weight_data);</div>
<div class="line">tensor conv1_bias(conv1_bias_desc_plain, eng, conv1_bias_data);</div>
<div class="line">tensor relu1_dst(relu1_dst_desc_plain, eng, relu1_dst_data);</div>
<div class="line">std::vector&lt;tensor&gt; out1_list {relu1_dst};</div>
<div class="line"> </div>
<div class="line">sycl_interop::execute(cp1, strm, {relu0_dst, conv1_weight, conv1_bias}, out1_list);</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<div class="footer">
    <script>
        $('#top').prependTo($('#side-nav'));
    </script>
    <div class="footer-wrapper">
        <hr>
        <ul class="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>