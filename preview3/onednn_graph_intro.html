<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>oneDNN Graph: Introduction to oneDNN Graph for Preview</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div class="mobile-nav"><i id="nav-btn"></i><a href="index.html">oneAPI Deep Neural Network Library Graph API (oneDNN Graph)</a></div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">
     <a href="index.html">
      <div id="full-name">oneAPI Deep Neural Network Library Graph API (oneDNN Graph)</div>
    </a>
   </div>
   <div id="projectbrief">Performance Library for DNN Graph Optimization</div>
   <div id="projectnumber">0.3.0</div>
  <div>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('onednn_graph_intro.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Introduction to oneDNN Graph for Preview </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_doc_README"></a> </p>
<h1><a class="anchor" id="autotoc_md35"></a>
Introduction</h1>
<p>oneDNN Graph API extends oneDNN with a unified high-level graph API for multiple AI hardware classes (CPU, GPU, accelerators). With a flexible graph interface, it maximizes the optimization opportunity for generating efficient code across a variety of Intel and non-Intel HW and can be closely integrated with ecosystem framework and inference engines. oneDNN Graph API accepts a deep learning computation graph as input and performs graph partitioning, where nodes that are candidates for fusion are grouped. oneDNN Graph compiles and executes a group of deep learning operations in a graph partition as a fused operation.</p>
<p><img src="oneDNN_graph_api.png" alt="" class="inline" title="oneDNN is extending to include graph API"/></p>
<p>With the graph as input, oneDNN Graph implementation can perform target-specific optimization and code generation on a larger scope, which allows it to map the operations to hardware resources and improve execution efficiency and data locality with a global view of the computation graph. With the rapid introduction of hardware support for dense compute, the deep learning workload characteristic changed significantly from a few hot spots on compute-intensive operations to a broad number of operations scattered across the applications. Accelerating a few compute-intensive operations using primitive API has diminishing returns and limits the performance potential. It is critical to have a graph API to better exploit hardware compute capacity.</p>
<p>oneDNN Graph API provides graph partition as a unified graph interface for different types of AI hardware classes. Users construct a graph with operations and logical tensors and pass it to oneDNN Graph implementation to get partitions. oneDNN Graph implementation has a chance to receive a full graph and decides the best way to partition, with the consideration of maximizing performance and coordinating with the application’s control of hardware resources. As the partition size can range from a single op to a full graph, it satisfies the different needs of graph size for compilation and execution on different AI hardware.</p>
<h1><a class="anchor" id="autotoc_md36"></a>
Programming model</h1>
<p>oneDNN Graph programming model allows users to pass a computation graph and get partitions. Users then compile partitions, bind tensor data, and execute compiled partitions. Partitions are decided by oneDNN Graph implementation, which is the key concept to satisfy the different needs of AI hardware classes using a unified API.</p>
<p><img src="oneDNN_graph_programming_model.png" alt="" class="inline" title="oneDNN graph programming model"/></p>
<p>oneDNN Graph API uses <code>logical tensor</code>, <code>op</code>, and <code>graph</code> to represent a computation graph. Logical tensor represents tensor’s metadata, like element data type, shape, and layout. OP represents an operation on a computation graph. OP has kind, attribute, and input and output logical tensors. OPs are added to the graph being constructed. As both OP and logical tensor contains a unique ID, the graph knows how to connect a producer OP to a consumer OP through a logical tensor. The graph constructed is immutable, and the sole purpose of the graph is to partition the graph. Once users get partitions, users should not add OP to the graph.</p>
<p>A <code>partition</code> is a connected subgraph within a graph. oneDNN Graph implementation analyzes a graph and returns a vector of partitions. The returned partitions must not form a dependence cycle. A partition needs to be compiled before execution. The compilation lowers down the compute logic to hardware ISA level and generates binary code. The generated code is specialized for the input and output tensor’s metadata. Users must specify the shape and layout for each logical tensor during compilation. Users must create new logical tensors to pass the enriched metadata with the compilation API. The new logical tensors must have the same IDs as the logical tensors passed at the graph construction time.</p>
<p>A <code>compiled partition</code> represents the generated code specialized for target hardware and tensor metadata passed with compilation API. To execute a compiled partition, users must pass input and output tensors. Input tensors must bind input data buffers to logical tensors. Users may query the compiled partition for output data buffer sizes. If the sizes are known, users may allocate the output data buffers and bind to output tensors. If the sizes are unknown, users must provide an allocator for oneDNN Graph implementation to allocate the output tensor buffer. The execution API takes a compiled partition, input tensors, and return output tensors with the data buffer updated.</p>
<p>An <code>engine</code> represents a target device and context in the system. It needs to be passed as a parameter for partition compilation. A <code>stream</code> abstracts hardware execution resources of a target device. It is required to execute a compiled partition.</p>
<p>oneDNN Graph API provides low precision support including both int8, bf16, and fp16. For int8, oneDNN Graph API supports quantized model with static quantization. For bf16 or fp16, oneDNN Graph supports deep learning framework’s auto mixed precision mechanism. In both cases, oneDNN Graph API expects users to convert the computation graph to low precision representation and specify the data’s precision and quantization parameters. oneDNN Graph API implementation should strictly respect the numeric precision of the computation. More details can be found at <a href="https://spec.oneapi.io/onednn-graph/latest/programming_model.html#low-precision-support">specification</a>.</p>
<h1><a class="anchor" id="autotoc_md37"></a>
Relation to oneDNN primitives programming model</h1>
<p>The Graph API is an addition to oneDNN’s current primitives programming model. It aims to works with the framework graph and identifies graph partitions to offload. The API allows the framework to pass the deep learning graph to oneDNN, which analyzes the graph and returns the partitions. The partition will be further compiled and executed as a fused operation in the framework graph.</p>
<p>The Graph API extends the current oneDNN’s post-ops attributes API to enable general mechanism of fusing DNN operations in the framework graph. oneDNN’s post-ops attributes API requires framework integration to perform explicit pattern match on the framework graph, so each new fusion capability requires framework modification. The Graph API performs the pattern match inside oneDNN, so new fusion capability can be enabled by just upgrading oneDNN library without requiring framework modification.</p>
<h1><a class="anchor" id="autotoc_md38"></a>
Framework Integration</h1>
<p><img src="oneDNN_graph_fwk_integration.png" alt="" class="inline" title="Framework integration with oneDNN graph"/></p>
<p>Deep learning framework provides a rich set of deep neural network (DNN) operations to developers to describe the deep learning computation graph. It typically has two modes of execution: imperative mode and graph mode. Imperative mode executes the DNN operation directly, and graph mode builds an internal representation (IR) for the computation graph, optimizes it, and then submits it to device runtime for execution.</p>
<p>oneDNN Graph API is to accelerate the graph mode. It is integrated into the graph optimizer after all the target-independent pass is done. It iterates the framework graph, converts framework OP to oneDNN Graph OP, and calls <code>add_op()</code> to pass the oneDNN Graph OP and its parameter tensors to oneDNN Graph. After passing all framework OP, it calls <code>get_partitions()</code> to return the partitions, and then replaces the partitions with fused ops.</p>
<p>When the framework executing a fused op, the fused op’s implementation is to call <code>compile()</code> which compiles its associated partition. Then it queries the compiled partition to get the sizes of output tensors, allocates memory for them, and calls <code>execute()</code> to execute the compiled partition. </p>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<div class="footer">
    <script>
        $('#top').prependTo($('#side-nav'));
    </script>
    <div class="footer-wrapper">
        <hr>
        <ul class="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>