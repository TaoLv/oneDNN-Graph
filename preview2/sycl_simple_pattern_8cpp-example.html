<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>oneDNN Graph: sycl_simple_pattern.cpp</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div class="mobile-nav"><i id="nav-btn"></i><a href="index.html">oneAPI Deep Neural Network Library Graph API (oneDNN Graph)</a></div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">
     <a href="index.html">
      <div id="full-name">oneAPI Deep Neural Network Library Graph API (oneDNN Graph)</div>
    </a>
   </div>
   <div id="projectbrief">Performance Library for DNN Graph Optimization</div>
   <div id="projectnumber">0.2.0</div>
  <div>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('sycl_simple_pattern_8cpp-example.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">sycl_simple_pattern.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<p>This is an example to demonstrate how to build a simple graph and run on SYCL device. </p><blockquote class="doxtable">
<p>Annotated version: <a class="el" href="sycl_simple_pattern_cpp.html">Getting started on both CPU and GPU with SYCL extensions API</a> </p>
</blockquote>
<div class="fragment"><div class="line"><span class="comment">/*******************************************************************************</span></div>
<div class="line"><span class="comment">* Copyright 2020-2021 Intel Corporation</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">* Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><span class="comment">* you may not use this file except in compliance with the License.</span></div>
<div class="line"><span class="comment">* You may obtain a copy of the License at</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">*     http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">* Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><span class="comment">* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><span class="comment">* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><span class="comment">* See the License for the specific language governing permissions and</span></div>
<div class="line"><span class="comment">* limitations under the License.</span></div>
<div class="line"><span class="comment">*******************************************************************************/</span></div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &lt;assert.h&gt;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &lt;algorithm&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;stdexcept&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;unordered_map&gt;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &quot;common/execution_context.hpp&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;common/helpers_any_layout.hpp&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;common/utils.hpp&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define assertm(exp, msg) assert(((void)msg, exp))</span></div>
<div class="line"> </div>
<div class="line"><span class="comment">//[Headers and namespace]</span></div>
<div class="line"><span class="preprocessor">#include &quot;oneapi/dnnl/dnnl_graph.hpp&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;oneapi/dnnl/dnnl_graph_sycl.hpp&quot;</span></div>
<div class="line"><span class="keyword">using namespace </span>dnnl::graph;</div>
<div class="line"><span class="keyword">using namespace </span>cl::sycl;</div>
<div class="line"><span class="comment">//[Headers and namespace]</span></div>
<div class="line"><span class="keyword">using</span> data_type = <a name="a0"></a><a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227">logical_tensor::data_type</a>;</div>
<div class="line"><span class="keyword">using</span> layout_type = <a name="a1"></a><a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867">logical_tensor::layout_type</a>;</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">void</span> sycl_simple_pattern_tutorial(<a name="a2"></a><a class="code" href="classdnnl_1_1graph_1_1engine.html#a425168b38184f5d22b9eebfb3193b40e">engine::kind</a> engine_kind) {</div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;========Example: Conv-&gt;ReLU-&gt;Conv-&gt;ReLU========\n&quot;</span>;</div>
<div class="line">    <span class="comment">// clang-format off</span></div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Create logical tensors and operators-----------&quot;</span>;</div>
<div class="line">    <span class="keyword">const</span> std::vector&lt;size_t&gt; logical_id {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10};</div>
<div class="line"> </div>
<div class="line">    std::vector&lt;int64_t&gt; input_dims {8, 3, 227, 227};</div>
<div class="line">    std::vector&lt;int64_t&gt; weight_dims {96, 3, 11, 11};</div>
<div class="line">    std::vector&lt;int64_t&gt; bias_dims {96};</div>
<div class="line">    std::vector&lt;int64_t&gt; weight1_dims {96, 96, 1, 1};</div>
<div class="line">    std::vector&lt;int64_t&gt; bias1_dims {96};</div>
<div class="line">    std::vector&lt;int64_t&gt; dst_dims {8, 96, 55, 55};</div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create graph]</span></div>
<div class="line">    graph g(engine_kind);</div>
<div class="line">    <span class="comment">//[Create graph]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create conv&#39;s logical tensor]</span></div>
<div class="line">    logical_tensor conv0_src_desc {logical_id[0], <a name="a3"></a><a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, input_dims, <a name="a4"></a><a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    logical_tensor conv0_weight_desc {logical_id[1], <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, weight_dims, <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    logical_tensor conv0_dst_desc {logical_id[2], <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, dst_dims, <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    <span class="comment">//[Create conv&#39;s logical tensor]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create first conv]</span></div>
<div class="line">    op conv0(0, op::kind::Convolution, {conv0_src_desc, conv0_weight_desc}, {conv0_dst_desc}, <span class="stringliteral">&quot;conv0&quot;</span>);</div>
<div class="line">    conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;strides&quot;</span>, {4, 4});</div>
<div class="line">    conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;pads_begin&quot;</span>, {0, 0});</div>
<div class="line">    conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;pads_end&quot;</span>, {0, 0});</div>
<div class="line">    conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;dilations&quot;</span>, {1, 1});</div>
<div class="line">    conv0.set_attr&lt;int64_t&gt;(<span class="stringliteral">&quot;groups&quot;</span>, 1);</div>
<div class="line">    conv0.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;data_format&quot;</span>, <span class="stringliteral">&quot;NCX&quot;</span>);</div>
<div class="line">    conv0.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;filter_format&quot;</span>, <span class="stringliteral">&quot;OIX&quot;</span>);</div>
<div class="line">    <span class="comment">//[Create first conv]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create biasadd&#39;s logical tensor]</span></div>
<div class="line">    logical_tensor conv0_bias_desc {logical_id[3], <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, bias_dims, <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    logical_tensor conv0_bias_add_dst_desc {logical_id[4], <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, dst_dims, <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    <span class="comment">//[Create biasadd&#39;s logical tensor]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create first bias_add]</span></div>
<div class="line">    op conv0_bias_add(1, op::kind::BiasAdd, {conv0_dst_desc, conv0_bias_desc}, {conv0_bias_add_dst_desc}, <span class="stringliteral">&quot;conv0_bias_add&quot;</span>);</div>
<div class="line">    <span class="comment">//[Create first bias_add]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create relu&#39;s logical tensor]</span></div>
<div class="line">    logical_tensor relu0_dst_desc {logical_id[5], <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, dst_dims, <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    <span class="comment">//[Create relu&#39;s logical tensor]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create first relu]</span></div>
<div class="line">    op relu0(2, op::kind::ReLU, {conv0_bias_add_dst_desc}, {relu0_dst_desc}, <span class="stringliteral">&quot;relu0&quot;</span>);</div>
<div class="line">    <span class="comment">//[Create first relu]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create conv&#39;s second logical tensor]</span></div>
<div class="line">    logical_tensor conv1_weight_desc {logical_id[6], <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, weight1_dims, <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    logical_tensor conv1_dst_desc {logical_id[7], <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, dst_dims, <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    <span class="comment">//[Create conv&#39;s second logical tensor]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create second conv]</span></div>
<div class="line">    op conv1(3, op::kind::Convolution, {relu0_dst_desc, conv1_weight_desc}, {conv1_dst_desc}, <span class="stringliteral">&quot;conv1&quot;</span>);</div>
<div class="line">    conv1.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;strides&quot;</span>, {1, 1});</div>
<div class="line">    conv1.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;pads_begin&quot;</span>, {0, 0});</div>
<div class="line">    conv1.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;pads_end&quot;</span>, {0, 0});</div>
<div class="line">    conv1.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;dilations&quot;</span>, {1, 1});</div>
<div class="line">    conv1.set_attr&lt;int64_t&gt;(<span class="stringliteral">&quot;groups&quot;</span>, 1);</div>
<div class="line">    conv1.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;data_format&quot;</span>, <span class="stringliteral">&quot;NCX&quot;</span>);</div>
<div class="line">    conv1.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;filter_format&quot;</span>, <span class="stringliteral">&quot;OIX&quot;</span>);</div>
<div class="line">    <span class="comment">//[Create second conv]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create biasadd&#39;s second logical tensor]</span></div>
<div class="line">    logical_tensor conv1_bias_desc {logical_id[8], <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, bias1_dims, <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    logical_tensor conv1_bias_add_dst_desc {logical_id[9], <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, dst_dims, <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    <span class="comment">//[Create biasadd&#39;s second logical tensor]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create second bias_add]</span></div>
<div class="line">    op conv1_bias_add(4, op::kind::BiasAdd, {conv1_dst_desc, conv1_bias_desc}, {conv1_bias_add_dst_desc}, <span class="stringliteral">&quot;conv1_bias_add&quot;</span>);</div>
<div class="line">    <span class="comment">//[Create second bias_add]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create relu&#39;s second logical tensor]</span></div>
<div class="line">    logical_tensor relu1_dst_desc {logical_id[10], <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">logical_tensor::data_type::f32</a>, dst_dims, <a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">logical_tensor::layout_type::strided</a>};</div>
<div class="line">    <span class="comment">//[Create relu&#39;s second logical tensor]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create second relu]</span></div>
<div class="line">    op relu1(5, op::kind::ReLU, {conv1_bias_add_dst_desc}, {relu1_dst_desc}, <span class="stringliteral">&quot;relu1&quot;</span>);</div>
<div class="line">    <span class="comment">//[Create second relu]</span></div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    std::unordered_map&lt;size_t, op::kind&gt; op_id_kind_map {{0, op::kind::Convolution},</div>
<div class="line">        {1, op::kind::BiasAdd}, {2, op::kind::ReLU}, {3, op::kind::Convolution},</div>
<div class="line">        {4, op::kind::BiasAdd}, {5, op::kind::ReLU}};</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Add OP to graph--------------------------------&quot;</span>;</div>
<div class="line">    <span class="comment">//[Add op]</span></div>
<div class="line">    g.add_op(conv0);</div>
<div class="line">    g.add_op(relu0);</div>
<div class="line">    g.add_op(conv1);</div>
<div class="line">    g.add_op(relu1);</div>
<div class="line">    g.add_op(conv0_bias_add);</div>
<div class="line">    g.add_op(conv1_bias_add);</div>
<div class="line">    <span class="comment">//[Add op]</span></div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Filter and get partition-----------------------&quot;</span>;</div>
<div class="line">    <span class="comment">//[Get partition]</span></div>
<div class="line">    <span class="keyword">auto</span> partitions = g.get_partitions();</div>
<div class="line">    <span class="comment">//[Get partition]</span></div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Number of returned partitions: &quot;</span> &lt;&lt; partitions.size() &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; partitions.size(); ++i) {</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Partition[&quot;</span> &lt;&lt; partitions[i].get_id()</div>
<div class="line">                  &lt;&lt; <span class="stringliteral">&quot;]&#39;s supporting status: &quot;</span></div>
<div class="line">                  &lt;&lt; (partitions[i].is_supported() ? <span class="stringliteral">&quot;true&quot;</span> : <span class="stringliteral">&quot;false&quot;</span>) &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    std::unordered_set&lt;size_t&gt; id_to_set_any_layout;</div>
<div class="line">    set_any_layout(partitions, id_to_set_any_layout);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create allocator]</span></div>
<div class="line">    allocator alloc = <a name="a5"></a><a class="code" href="namespacednnl_1_1graph_1_1sycl__interop.html#afbfd5202a21eebb29d010f14bcbbbb13">sycl_interop::make_allocator</a>(sycl_malloc_wrapper, sycl_free_wrapper);</div>
<div class="line">    <span class="comment">//[Create allocator]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Define sycl queue]</span></div>
<div class="line">    sycl::queue q = (engine_kind == <a name="a6"></a><a class="code" href="classdnnl_1_1graph_1_1engine.html#a425168b38184f5d22b9eebfb3193b40ea0aa0be2a866411d9ff03515227454947">engine::kind::gpu</a>) ? sycl::queue(gpu_selector {}, sycl::property::queue::in_order {}) : sycl::queue(cpu_selector {}, sycl::property::queue::in_order {});</div>
<div class="line">    <span class="comment">//[Define sycl queue]</span></div>
<div class="line"> </div>
<div class="line">    <span class="comment">//[Create engine]</span></div>
<div class="line">    engine eng = <a name="a7"></a><a class="code" href="namespacednnl_1_1graph_1_1sycl__interop.html#acce9d60bb72aa57ca446c3ea1b575879">sycl_interop::make_engine</a>(q.get_device(), q.get_context());</div>
<div class="line">    eng.set_allocator(alloc);</div>
<div class="line">    <span class="comment">//[Create engine]</span></div>
<div class="line">    </div>
<div class="line">    <span class="comment">//[Create stream]</span></div>
<div class="line">    <span class="keyword">auto</span> strm = <a name="a8"></a><a class="code" href="namespacednnl_1_1graph_1_1sycl__interop.html#abb9c8e2fb51978c435dce3224bf1c790">sycl_interop::make_stream</a>(eng, q);</div>
<div class="line">    <span class="comment">//[Create stream]</span></div>
<div class="line">    </div>
<div class="line">    std::vector&lt;compiled_partition&gt; c_partitions(partitions.size());</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// mapping from id to tensors</span></div>
<div class="line">    <span class="comment">// need provide queue for later buffer deallocation</span></div>
<div class="line">    <a name="_a9"></a><a class="code" href="classtensor__map.html">tensor_map</a> tm {q};</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// mapping from id to queried logical tensor from compiled partition</span></div>
<div class="line">    <span class="comment">// used to record the logical tensors that are previously enabled with ANY layout</span></div>
<div class="line">    std::unordered_map&lt;size_t, logical_tensor&gt; id_to_queried_logical_tensors;</div>
<div class="line"> </div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; partitions.size(); ++i) {</div>
<div class="line">        <span class="keywordflow">if</span> (partitions[i].is_supported()) {</div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;\nPartition[&quot;</span> &lt;&lt; partitions[i].get_id() &lt;&lt; <span class="stringliteral">&quot;] is being processed.\n&quot;</span>;</div>
<div class="line">            std::vector&lt;logical_tensor&gt; inputs = partitions[i].get_in_ports();</div>
<div class="line">            std::vector&lt;logical_tensor&gt; outputs = partitions[i].get_out_ports();</div>
<div class="line"> </div>
<div class="line">            replace_with_queried_logical_tensors(inputs, id_to_queried_logical_tensors);</div>
<div class="line"> </div>
<div class="line">            update_tensors_with_any_layout(outputs, id_to_set_any_layout);</div>
<div class="line"> </div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Compiling--------------------------------------&quot;</span>;</div>
<div class="line">            <span class="comment">//[Compile partition]</span></div>
<div class="line">            c_partitions[i] = partitions[i].compile(inputs, outputs, eng);</div>
<div class="line">            <span class="comment">//[Compile partition]</span></div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">            record_queried_logical_tensors(partitions[i].get_out_ports(), c_partitions[i],</div>
<div class="line">                id_to_queried_logical_tensors);</div>
<div class="line"> </div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Creating tensors and allocating memory buffer--&quot;</span>;</div>
<div class="line">            std::vector&lt;tensor&gt; input_ts = tm.construct_and_initialize_tensors(inputs, c_partitions[i], 1);</div>
<div class="line">            std::vector&lt;tensor&gt; output_ts = tm.construct_and_initialize_tensors(outputs, c_partitions[i], 0);</div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Executing compiled partition-------------------&quot;</span>;</div>
<div class="line">            <span class="comment">//[Execute compiled partition]</span></div>
<div class="line">            <a name="a10"></a><a class="code" href="namespacednnl_1_1graph_1_1sycl__interop.html#a6bd3e03d093957ceba0ba8a58a6e73ba">sycl_interop::execute</a>(c_partitions[i], strm, input_ts, output_ts);</div>
<div class="line">            <span class="comment">//[Execute compiled partition]</span></div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line">        } <span class="keywordflow">else</span> {</div>
<div class="line">            std::vector&lt;size_t&gt; unsupported_op_ids = partitions[i].get_ops();</div>
<div class="line">            assertm(unsupported_op_ids.size() == 1, <span class="stringliteral">&quot;Unsupported partition only &quot;</span></div>
<div class="line">                <span class="stringliteral">&quot;contains single op.&quot;</span>);</div>
<div class="line">            <span class="keywordflow">if</span> (op_id_kind_map[unsupported_op_ids[0]] == op::kind::Wildcard) {</div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;\nWarning (actually an error): partition &quot;</span> &lt;&lt; partitions[i].get_id() &lt;&lt;</div>
<div class="line">                        <span class="stringliteral">&quot; contains only a Wildcard op which cannot be computed.\n&quot;</span>;</div>
<div class="line">            } <span class="keywordflow">else</span> {</div>
<div class="line">                <span class="keywordflow">continue</span>;</div>
<div class="line">            }</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">    <span class="comment">// wait for all compiled partition&#39;s execution finished</span></div>
<div class="line">    strm.wait();</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Check correctness------------------------------&quot;</span>;</div>
<div class="line">    <span class="comment">//[Check results]</span></div>
<div class="line">    <span class="keywordtype">float</span> expected_result</div>
<div class="line">            = (1 * 11 * 11 * 3 + <span class="comment">/* conv0 bias */</span> 1.0f) * (1 * 1 * 96)</div>
<div class="line">            + <span class="comment">/* conv1 bias */</span> 1.0f;</div>
<div class="line">    <span class="keywordtype">float</span> *actual_output_ptr = tm.get(relu1_dst_desc.get_id()).get_data_handle&lt;float&gt;();</div>
<div class="line">    <span class="keyword">auto</span> output_dims = relu1_dst_desc.get_dims();</div>
<div class="line">    <span class="keyword">auto</span> num_elem = product(output_dims);</div>
<div class="line">    std::vector&lt;float&gt; expected_output(num_elem, expected_result);</div>
<div class="line">    compare_data(expected_output.data(), actual_output_ptr, num_elem);</div>
<div class="line">    <span class="comment">//[Check results]</span></div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;============Run Example Successfully===========\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// clang-format on</span></div>
<div class="line">}</div>
<div class="line"> </div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> **argv) {</div>
<div class="line">    <a class="code" href="classdnnl_1_1graph_1_1engine.html#a425168b38184f5d22b9eebfb3193b40e">engine::kind</a> engine_kind = parse_engine_kind(argc, argv);</div>
<div class="line">    sycl_simple_pattern_tutorial(engine_kind);</div>
<div class="line">    <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1engine_html_a425168b38184f5d22b9eebfb3193b40e"><div class="ttname"><a href="classdnnl_1_1graph_1_1engine.html#a425168b38184f5d22b9eebfb3193b40e">dnnl::graph::engine::kind</a></div><div class="ttdeci">kind</div><div class="ttdoc">engine kind</div><div class="ttdef"><b>Definition:</b> dnnl_graph.hpp:102</div></div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1engine_html_a425168b38184f5d22b9eebfb3193b40ea0aa0be2a866411d9ff03515227454947"><div class="ttname"><a href="classdnnl_1_1graph_1_1engine.html#a425168b38184f5d22b9eebfb3193b40ea0aa0be2a866411d9ff03515227454947">dnnl::graph::engine::kind::gpu</a></div><div class="ttdeci">@ gpu</div><div class="ttdoc">GPU engine.</div></div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1logical__tensor_html_acddb1dc65b7b4feede7710a719f32227"><div class="ttname"><a href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227">dnnl::graph::logical_tensor::data_type</a></div><div class="ttdeci">data_type</div><div class="ttdoc">Data Type.</div><div class="ttdef"><b>Definition:</b> dnnl_graph.hpp:302</div></div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1logical__tensor_html_acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e"><div class="ttname"><a href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227a512dc597be7ae761876315165dc8bd2e">dnnl::graph::logical_tensor::data_type::f32</a></div><div class="ttdeci">@ f32</div><div class="ttdoc">32-bit/single-precision floating point.</div></div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1logical__tensor_html_ad3fcaff44671577e56adb03b770f4867"><div class="ttname"><a href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867">dnnl::graph::logical_tensor::layout_type</a></div><div class="ttdeci">layout_type</div><div class="ttdoc">Layout type.</div><div class="ttdef"><b>Definition:</b> dnnl_graph.hpp:319</div></div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1logical__tensor_html_ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd"><div class="ttname"><a href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867a67a4043caf23a1d1393e5740873578bd">dnnl::graph::logical_tensor::layout_type::strided</a></div><div class="ttdeci">@ strided</div><div class="ttdoc">strided means that the layout is determined by the strides field.</div></div>
<div class="ttc" id="aclasstensor__map_html"><div class="ttname"><a href="classtensor__map.html">tensor_map</a></div><div class="ttdoc">A mapping from id to tensor is used to manage the lifecycle of all created tensors since these tensor...</div><div class="ttdef"><b>Definition:</b> execution_context.hpp:53</div></div>
<div class="ttc" id="anamespacednnl_1_1graph_1_1sycl__interop_html_a6bd3e03d093957ceba0ba8a58a6e73ba"><div class="ttname"><a href="namespacednnl_1_1graph_1_1sycl__interop.html#a6bd3e03d093957ceba0ba8a58a6e73ba">dnnl::graph::sycl_interop::execute</a></div><div class="ttdeci">cl::sycl::event execute(compiled_partition &amp;c_partition, stream &amp;astream, const std::vector&lt; tensor &gt; &amp;inputs, std::vector&lt; tensor &gt; &amp;outputs, const std::vector&lt; cl::sycl::event &gt; &amp;deps={})</div><div class="ttdoc">Executes a compiled partition in a specified stream and returns a SYCL event.</div><div class="ttdef"><b>Definition:</b> dnnl_graph_sycl.hpp:103</div></div>
<div class="ttc" id="anamespacednnl_1_1graph_1_1sycl__interop_html_abb9c8e2fb51978c435dce3224bf1c790"><div class="ttname"><a href="namespacednnl_1_1graph_1_1sycl__interop.html#abb9c8e2fb51978c435dce3224bf1c790">dnnl::graph::sycl_interop::make_stream</a></div><div class="ttdeci">stream make_stream(engine aengine, const cl::sycl::queue &amp;aqueue)</div><div class="ttdoc">Creates an execution stream for a given engine associated with a SYCL queue.</div><div class="ttdef"><b>Definition:</b> dnnl_graph_sycl.hpp:85</div></div>
<div class="ttc" id="anamespacednnl_1_1graph_1_1sycl__interop_html_acce9d60bb72aa57ca446c3ea1b575879"><div class="ttname"><a href="namespacednnl_1_1graph_1_1sycl__interop.html#acce9d60bb72aa57ca446c3ea1b575879">dnnl::graph::sycl_interop::make_engine</a></div><div class="ttdeci">engine make_engine(const cl::sycl::device &amp;adevice, const cl::sycl::context &amp;acontext)</div><div class="ttdoc">Constructs an engine from SYCL device and context objects.</div><div class="ttdef"><b>Definition:</b> dnnl_graph_sycl.hpp:68</div></div>
<div class="ttc" id="anamespacednnl_1_1graph_1_1sycl__interop_html_afbfd5202a21eebb29d010f14bcbbbb13"><div class="ttname"><a href="namespacednnl_1_1graph_1_1sycl__interop.html#afbfd5202a21eebb29d010f14bcbbbb13">dnnl::graph::sycl_interop::make_allocator</a></div><div class="ttdeci">allocator make_allocator(dnnl_graph_sycl_allocate_f sycl_malloc, dnnl_graph_sycl_deallocate_f sycl_free)</div><div class="ttdoc">Constructs an allocator from SYCL malloc and free function pointer.</div><div class="ttdef"><b>Definition:</b> dnnl_graph_sycl.hpp:53</div></div>
</div><!-- fragment --> </div><!-- contents -->
</div><!-- doc-content -->
<div class="footer">
    <script>
        $('#top').prependTo($('#side-nav'));
    </script>
    <div class="footer-wrapper">
        <hr>
        <ul class="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>