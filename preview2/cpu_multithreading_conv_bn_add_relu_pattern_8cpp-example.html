<!-- HTML header for doxygen 1.8.5-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>oneDNN Graph: cpu_multithreading_conv_bn_add_relu_pattern.cpp</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
  $(document).ready(function() { init_search(); });
/* @license-end */
</script>
<script src="assets/mathjax/MathJax.js?config=TeX-AMS_CHTML,dnnl"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="assets/customdoxygen.css" rel="stylesheet" type="text/css" />
<script type="text/javascript" src="assets/dnn.js"></script>
</head>
<body>
<div class="mobile-nav"><i id="nav-btn"></i><a href="index.html">oneAPI Deep Neural Network Library Graph API (oneDNN Graph)</a></div>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
   <div id="projectname">
     <a href="index.html">
      <div id="full-name">oneAPI Deep Neural Network Library Graph API (oneDNN Graph)</div>
    </a>
   </div>
   <div id="projectbrief">Performance Library for DNN Graph Optimization</div>
   <div id="projectnumber">0.2.0</div>
  <div>        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.svg"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.svg" alt=""/></a>
          </span>
        </div>
</div>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('cpu_multithreading_conv_bn_add_relu_pattern_8cpp-example.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="headertitle">
<div class="title">cpu_multithreading_conv_bn_add_relu_pattern.cpp</div>  </div>
</div><!--header-->
<div class="contents">
<blockquote class="doxtable">
<p>Example code: <a class="el" href="cpu_multithreading_conv_bn_add_relu_pattern_8cpp-example.html">cpu_multithreading_conv_bn_add_relu_pattern.cpp</a> </p>
</blockquote>
<blockquote class="doxtable">
<p>Annotated version: <a class="el" href="cpu_multithreading_conv_bn_add_relu_pattern_cpp.html">CPU example for multithread conv+bn+add+relu pattern</a> </p>
</blockquote>
<div class="fragment"><div class="line"><span class="comment">/*******************************************************************************</span></div>
<div class="line"><span class="comment">* Copyright 2020-2021 Intel Corporation</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">* Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></div>
<div class="line"><span class="comment">* you may not use this file except in compliance with the License.</span></div>
<div class="line"><span class="comment">* You may obtain a copy of the License at</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">*     http://www.apache.org/licenses/LICENSE-2.0</span></div>
<div class="line"><span class="comment">*</span></div>
<div class="line"><span class="comment">* Unless required by applicable law or agreed to in writing, software</span></div>
<div class="line"><span class="comment">* distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></div>
<div class="line"><span class="comment">* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></div>
<div class="line"><span class="comment">* See the License for the specific language governing permissions and</span></div>
<div class="line"><span class="comment">* limitations under the License.</span></div>
<div class="line"><span class="comment">*******************************************************************************/</span></div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &lt;assert.h&gt;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &lt;algorithm&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;iostream&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;stdexcept&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;string&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;thread&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;vector&gt;</span></div>
<div class="line"><span class="preprocessor">#include &lt;unordered_map&gt;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &quot;oneapi/dnnl/dnnl_graph.hpp&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#include &quot;common/execution_context.hpp&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;common/helpers_any_layout.hpp&quot;</span></div>
<div class="line"><span class="preprocessor">#include &quot;common/utils.hpp&quot;</span></div>
<div class="line"> </div>
<div class="line"><span class="preprocessor">#define assertm(exp, msg) assert(((void)msg, exp))</span></div>
<div class="line"> </div>
<div class="line"><span class="keyword">using namespace </span>dnnl::graph;</div>
<div class="line"><span class="keyword">using</span> data_type = <a name="a0"></a><a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227">logical_tensor::data_type</a>;</div>
<div class="line"><span class="keyword">using</span> layout_type = <a name="a1"></a><a class="code" href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867">logical_tensor::layout_type</a>;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// digraph G {</span></div>
<div class="line"><span class="comment">// Wildcard_100002 -&gt; Convolution_100003;</span></div>
<div class="line"><span class="comment">// Convolution_100003 -&gt; BatchNormInference_100004;</span></div>
<div class="line"><span class="comment">// BatchNormInference_100004 -&gt; ReLU_100005;</span></div>
<div class="line"><span class="comment">// ReLU_100005 -&gt; Convolution_100006;</span></div>
<div class="line"><span class="comment">// Convolution_100006 -&gt; BatchNormInference_100007;</span></div>
<div class="line"><span class="comment">// BatchNormInference_100007 -&gt; Add_100008;</span></div>
<div class="line"><span class="comment">// Wildcard_100002 -&gt; Add_100008;</span></div>
<div class="line"><span class="comment">// Add_100008 -&gt; ReLU_100009;</span></div>
<div class="line"><span class="comment">// }</span></div>
<div class="line"><span class="comment">// clang-format off</span></div>
<div class="line"><span class="keywordtype">int</span> main(<span class="keywordtype">int</span> argc, <span class="keywordtype">char</span> **argv) {</div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;========Example: Conv+BN+ReLU+Conv+BN+Add+ReLU========\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    <a name="a2"></a><a class="code" href="classdnnl_1_1graph_1_1engine.html#a425168b38184f5d22b9eebfb3193b40e">engine::kind</a> engine_kind = parse_engine_kind(argc, argv);</div>
<div class="line">    <span class="keywordflow">if</span> (engine_kind == <a name="a3"></a><a class="code" href="classdnnl_1_1graph_1_1engine.html#a425168b38184f5d22b9eebfb3193b40ea0aa0be2a866411d9ff03515227454947">engine::kind::gpu</a>) {</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Don&#39;t support gpu now\n&quot;</span>;</div>
<div class="line">        <span class="keywordflow">return</span> -1;</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// Step 2: Construct a graph</span></div>
<div class="line">    graph g(engine_kind);</div>
<div class="line"> </div>
<div class="line">    <span class="keyword">auto</span> &amp;id_mgr = logical_id_manager::get();</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Create logical tensor--------------------------&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    std::vector&lt;int64_t&gt; input_dims {8, 56, 56, 256};</div>
<div class="line">    std::vector&lt;int64_t&gt; conv0_weight_dims {64, 256, 1, 1};</div>
<div class="line">    std::vector&lt;int64_t&gt; conv0_bias_dims {64};</div>
<div class="line">    std::vector&lt;int64_t&gt; conv0_dst_dims {8, 56, 56, 64};</div>
<div class="line"> </div>
<div class="line">    std::vector&lt;int64_t&gt; conv1_weight_dims {256, 64, 1, 1};</div>
<div class="line">    std::vector&lt;int64_t&gt; conv1_bias_dims {256};</div>
<div class="line">    std::vector&lt;int64_t&gt; conv1_dst_dims {8, 56, 56, 256};</div>
<div class="line"> </div>
<div class="line">    logical_tensor conv0_src_desc {id_mgr[<span class="stringliteral">&quot;conv0_src&quot;</span>], data_type::f32, input_dims, layout_type::strided};</div>
<div class="line">    logical_tensor conv0_weight_desc {id_mgr[<span class="stringliteral">&quot;conv0_weight&quot;</span>], data_type::f32, conv0_weight_dims, layout_type::strided};</div>
<div class="line">    logical_tensor conv0_dst_desc {id_mgr[<span class="stringliteral">&quot;conv0_dst&quot;</span>], data_type::f32, conv0_dst_dims, layout_type::strided};</div>
<div class="line">    </div>
<div class="line">    op input0 {id_mgr[<span class="stringliteral">&quot;input0&quot;</span>], op::kind::Wildcard, {}, {conv0_src_desc}, <span class="stringliteral">&quot;input0&quot;</span>};</div>
<div class="line"> </div>
<div class="line">    op conv0 {id_mgr[<span class="stringliteral">&quot;conv0&quot;</span>], op::kind::Convolution, {conv0_src_desc, conv0_weight_desc}, {conv0_dst_desc}, <span class="stringliteral">&quot;conv0&quot;</span>};</div>
<div class="line">    conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;strides&quot;</span>, {1, 1});</div>
<div class="line">    conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;pads_begin&quot;</span>, {0, 0});</div>
<div class="line">    conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;pads_end&quot;</span>, {0, 0});</div>
<div class="line">    conv0.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;dilations&quot;</span>, {1, 1});</div>
<div class="line">    conv0.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;data_format&quot;</span>, <span class="stringliteral">&quot;NXC&quot;</span>);</div>
<div class="line">    conv0.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;filter_format&quot;</span>, <span class="stringliteral">&quot;OIX&quot;</span>);</div>
<div class="line">    conv0.set_attr&lt;int64_t&gt;(<span class="stringliteral">&quot;groups&quot;</span>, 1);</div>
<div class="line">    </div>
<div class="line">    logical_tensor bn0_scale_desc {id_mgr[<span class="stringliteral">&quot;bn0_scale&quot;</span>], data_type::f32, conv0_bias_dims, layout_type::strided};</div>
<div class="line">    logical_tensor bn0_shift_desc {id_mgr[<span class="stringliteral">&quot;bn0_shift&quot;</span>], data_type::f32, conv0_bias_dims, layout_type::strided};</div>
<div class="line">    logical_tensor bn0_mean_desc {id_mgr[<span class="stringliteral">&quot;bn0_mean&quot;</span>], data_type::f32, conv0_bias_dims, layout_type::strided};</div>
<div class="line">    logical_tensor bn0_var_desc {id_mgr[<span class="stringliteral">&quot;bn0_var&quot;</span>], data_type::f32, conv0_bias_dims, layout_type::strided};</div>
<div class="line">    logical_tensor bn0_dst_desc {id_mgr[<span class="stringliteral">&quot;bn0_dst&quot;</span>], data_type::f32, conv0_dst_dims, layout_type::strided};</div>
<div class="line">    </div>
<div class="line">    op bn0 {id_mgr[<span class="stringliteral">&quot;bn0&quot;</span>], op::kind::BatchNormInference, {conv0_dst_desc, bn0_scale_desc, bn0_shift_desc, bn0_mean_desc, bn0_var_desc}, {bn0_dst_desc}, <span class="stringliteral">&quot;bn0&quot;</span>};</div>
<div class="line">    bn0.set_attr&lt;<span class="keywordtype">float</span>&gt;(<span class="stringliteral">&quot;epsilon&quot;</span>, 0.f);</div>
<div class="line">    bn0.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;data_format&quot;</span>, <span class="stringliteral">&quot;NXC&quot;</span>);</div>
<div class="line"> </div>
<div class="line">    logical_tensor relu0_dst_desc {id_mgr[<span class="stringliteral">&quot;relu0_dst&quot;</span>], data_type::f32, conv0_dst_dims, layout_type::strided};</div>
<div class="line"> </div>
<div class="line">    op relu0 {id_mgr[<span class="stringliteral">&quot;relu0&quot;</span>], op::kind::ReLU, {bn0_dst_desc}, {relu0_dst_desc}, <span class="stringliteral">&quot;relu0&quot;</span>};</div>
<div class="line"> </div>
<div class="line">    logical_tensor conv1_weight_desc {id_mgr[<span class="stringliteral">&quot;conv1_weight&quot;</span>], data_type::f32, conv1_weight_dims, layout_type::strided};</div>
<div class="line">    logical_tensor conv1_dst_desc {id_mgr[<span class="stringliteral">&quot;conv1_dst&quot;</span>], data_type::f32, conv1_dst_dims, layout_type::strided};</div>
<div class="line">    </div>
<div class="line">    op conv1 {id_mgr[<span class="stringliteral">&quot;conv1&quot;</span>], op::kind::Convolution, {relu0_dst_desc, conv1_weight_desc}, {conv1_dst_desc}, <span class="stringliteral">&quot;conv1&quot;</span>};</div>
<div class="line">    conv1.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;strides&quot;</span>, {1, 1});</div>
<div class="line">    conv1.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;pads_begin&quot;</span>, {0, 0});</div>
<div class="line">    conv1.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;pads_end&quot;</span>, {0, 0});</div>
<div class="line">    conv1.set_attr&lt;std::vector&lt;int64_t&gt;&gt;(<span class="stringliteral">&quot;dilations&quot;</span>, {1, 1});</div>
<div class="line">    conv1.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;data_format&quot;</span>, <span class="stringliteral">&quot;NXC&quot;</span>);</div>
<div class="line">    conv1.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;filter_format&quot;</span>, <span class="stringliteral">&quot;OIX&quot;</span>);</div>
<div class="line">    conv1.set_attr&lt;int64_t&gt;(<span class="stringliteral">&quot;groups&quot;</span>, 1);</div>
<div class="line"> </div>
<div class="line">    logical_tensor bn1_scale_desc {id_mgr[<span class="stringliteral">&quot;bn1_scale&quot;</span>], data_type::f32, conv1_bias_dims, layout_type::strided};</div>
<div class="line">    logical_tensor bn1_shift_desc {id_mgr[<span class="stringliteral">&quot;bn1_shift&quot;</span>], data_type::f32, conv1_bias_dims, layout_type::strided};</div>
<div class="line">    logical_tensor bn1_mean_desc {id_mgr[<span class="stringliteral">&quot;bn1_mean&quot;</span>], data_type::f32, conv1_bias_dims, layout_type::strided};</div>
<div class="line">    logical_tensor bn1_var_desc {id_mgr[<span class="stringliteral">&quot;bn1_var&quot;</span>], data_type::f32, conv1_bias_dims, layout_type::strided};</div>
<div class="line">    logical_tensor bn1_dst_desc {id_mgr[<span class="stringliteral">&quot;bn1_dst&quot;</span>], data_type::f32, conv1_dst_dims, layout_type::strided};</div>
<div class="line">    logical_tensor add0_src_desc {id_mgr[<span class="stringliteral">&quot;add0_src&quot;</span>], data_type::f32, input_dims, layout_type::strided};</div>
<div class="line">    </div>
<div class="line">    op bn1 {id_mgr[<span class="stringliteral">&quot;bn1&quot;</span>], op::kind::BatchNormInference, {conv1_dst_desc, bn1_scale_desc, bn1_shift_desc, bn1_mean_desc, bn1_var_desc}, {bn1_dst_desc}, <span class="stringliteral">&quot;bn1&quot;</span>};</div>
<div class="line">    bn1.set_attr&lt;<span class="keywordtype">float</span>&gt;(<span class="stringliteral">&quot;epsilon&quot;</span>, 0.f);</div>
<div class="line">    bn1.set_attr&lt;std::string&gt;(<span class="stringliteral">&quot;data_format&quot;</span>, <span class="stringliteral">&quot;NXC&quot;</span>);</div>
<div class="line"> </div>
<div class="line">    logical_tensor add0_dst_desc {id_mgr[<span class="stringliteral">&quot;add0_dst&quot;</span>], data_type::f32, conv1_dst_dims, layout_type::strided};</div>
<div class="line"> </div>
<div class="line">    op add0 {id_mgr[<span class="stringliteral">&quot;add0&quot;</span>], op::kind::Add, {bn1_dst_desc, add0_src_desc}, {add0_dst_desc}, <span class="stringliteral">&quot;add0&quot;</span>};</div>
<div class="line"> </div>
<div class="line">    logical_tensor relu1_dst_desc {id_mgr[<span class="stringliteral">&quot;relu1_dst&quot;</span>], data_type::f32, conv1_dst_dims, layout_type::strided};</div>
<div class="line">    </div>
<div class="line">    op relu1 {id_mgr[<span class="stringliteral">&quot;relu1&quot;</span>], op::kind::ReLU, {add0_dst_desc}, {relu1_dst_desc}, <span class="stringliteral">&quot;relu1&quot;</span>};</div>
<div class="line"> </div>
<div class="line">    op end {id_mgr[<span class="stringliteral">&quot;end&quot;</span>], op::kind::End, {relu1_dst_desc}, {}, <span class="stringliteral">&quot;end&quot;</span>};</div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    std::unordered_map&lt;size_t, op::kind&gt; op_id_kind_map {{id_mgr[<span class="stringliteral">&quot;input0&quot;</span>], op::kind::Wildcard},</div>
<div class="line">        {id_mgr[<span class="stringliteral">&quot;conv0&quot;</span>], op::kind::Convolution}, {id_mgr[<span class="stringliteral">&quot;bn0&quot;</span>], op::kind::BatchNormInference},</div>
<div class="line">        {id_mgr[<span class="stringliteral">&quot;relu0&quot;</span>], op::kind::ReLU}, {id_mgr[<span class="stringliteral">&quot;conv1&quot;</span>], op::kind::Convolution}, {id_mgr[<span class="stringliteral">&quot;bn1&quot;</span>], op::kind::BatchNormInference},</div>
<div class="line">        {id_mgr[<span class="stringliteral">&quot;add0&quot;</span>], op::kind::Add}, {id_mgr[<span class="stringliteral">&quot;relu1&quot;</span>], op::kind::ReLU}, {id_mgr[<span class="stringliteral">&quot;end&quot;</span>], op::kind::End}};</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Add OP to graph--------------------------------&quot;</span>;</div>
<div class="line">    g.add_op(input0);</div>
<div class="line">    g.add_op(conv0);</div>
<div class="line">    g.add_op(bn0);</div>
<div class="line">    g.add_op(relu0);</div>
<div class="line">    g.add_op(conv1);</div>
<div class="line">    g.add_op(bn1);</div>
<div class="line">    g.add_op(add0);</div>
<div class="line">    g.add_op(relu1);</div>
<div class="line">    g.add_op(end);</div>
<div class="line">    id_mgr.freeze(); <span class="comment">// graph is built up, and the arguments set could be frozen</span></div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// Step 3: Filter and get partitions</span></div>
<div class="line"><span class="comment"></span>    std::cout &lt;&lt; <span class="stringliteral">&quot;Filter and get partition-----------------------&quot;</span>;</div>
<div class="line">    <span class="keyword">auto</span> partitions = g.get_partitions(<a name="a4"></a><a class="code" href="classdnnl_1_1graph_1_1partition.html#a439c0490ea8ea85f2a12ec7b320a9a3ca051de32597041e41f73b97d61c67a13b">partition::policy::fusion</a>);</div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Number of returned partitions: &quot;</span> &lt;&lt; partitions.size() &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; partitions.size(); ++i) {</div>
<div class="line">        std::cout &lt;&lt; <span class="stringliteral">&quot;Partition[&quot;</span> &lt;&lt; partitions[i].get_id()</div>
<div class="line">                  &lt;&lt; <span class="stringliteral">&quot;]&#39;s supporting status: &quot;</span></div>
<div class="line">                  &lt;&lt; (partitions[i].is_supported() ? <span class="stringliteral">&quot;true&quot;</span> : <span class="stringliteral">&quot;false&quot;</span>) &lt;&lt; <span class="stringliteral">&quot;\n&quot;</span>;</div>
<div class="line">    }</div>
<div class="line"> </div>
<div class="line">    std::unordered_set&lt;size_t&gt; id_to_set_any_layout;</div>
<div class="line">    set_any_layout(partitions, id_to_set_any_layout);</div>
<div class="line"> </div>
<div class="line">    <span class="keywordtype">int</span> device_id = 0;</div>
<div class="line">    engine e {engine_kind, device_id};</div>
<div class="line"> </div>
<div class="line">    stream s {e};</div>
<div class="line"> </div>
<div class="line">    std::vector&lt;compiled_partition&gt; c_partitions(partitions.size());</div>
<div class="line"> </div>
<div class="line">    <span class="keywordtype">size_t</span> thread_num = 8; </div>
<div class="line"> </div>
<div class="line">    <span class="comment">// mapping from id to tensors</span></div>
<div class="line">    std::vector&lt;tensor_map&gt; tms(thread_num);</div>
<div class="line"> </div>
<div class="line">    <span class="comment">// mapping from id to queried logical tensor from compiled partition</span></div>
<div class="line">    <span class="comment">// used to record the logical tensors that are previously enabled with ANY layout</span></div>
<div class="line">    std::unordered_map&lt;size_t, logical_tensor&gt; id_to_queried_logical_tensors;</div>
<div class="line"> </div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; partitions.size(); ++i) {</div>
<div class="line">        <span class="keywordflow">if</span> (partitions[i].is_supported()) {</div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;\nPartition[&quot;</span> &lt;&lt; partitions[i].get_id() &lt;&lt; <span class="stringliteral">&quot;] is being processed.\n&quot;</span>;</div>
<div class="line">            std::vector&lt;logical_tensor&gt; inputs = partitions[i].get_in_ports();</div>
<div class="line">            std::vector&lt;logical_tensor&gt; outputs = partitions[i].get_out_ports();</div>
<div class="line"> </div>
<div class="line">            replace_with_queried_logical_tensors(inputs, id_to_queried_logical_tensors);</div>
<div class="line"> </div>
<div class="line">            update_tensors_with_any_layout(outputs, id_to_set_any_layout);</div>
<div class="line"> </div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Compiling--------------------------------------&quot;</span>;</div>
<div class="line">            c_partitions[i] = partitions[i].compile(inputs, outputs, e);</div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">            record_queried_logical_tensors(partitions[i].get_out_ports(), c_partitions[i],</div>
<div class="line">                id_to_queried_logical_tensors);</div>
<div class="line"> </div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Executing compiled partition-------------------&quot;</span>;</div>
<div class="line">            <span class="keyword">auto</span> thread_func = [&amp;](<span class="keywordtype">size_t</span> tid) {</div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;Start thread &quot;</span> &lt;&lt; tid &lt;&lt; std::endl;</div>
<div class="line">                std::vector&lt;tensor&gt; input_ts = tms[tid].construct_and_initialize_tensors(inputs, c_partitions[i], 1);</div>
<div class="line">                std::vector&lt;tensor&gt; output_ts = tms[tid].construct_and_initialize_tensors(outputs, c_partitions[i], 0);</div>
<div class="line">                stream s {e};</div>
<div class="line"> </div>
<div class="line">                c_partitions[i].execute(s, input_ts, output_ts);</div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;End thread &quot;</span> &lt;&lt; tid &lt;&lt; std::endl;</div>
<div class="line"> </div>
<div class="line">            };</div>
<div class="line"> </div>
<div class="line">            std::vector&lt;std::thread&gt; workers;</div>
<div class="line">            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> t_num=0; t_num &lt; thread_num; t_num++) {</div>
<div class="line">                workers.emplace_back(thread_func, t_num);</div>
<div class="line">            }</div>
<div class="line"> </div>
<div class="line">            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> t_num=0; t_num &lt; thread_num; t_num++) {</div>
<div class="line">                workers[t_num].join();</div>
<div class="line">            }</div>
<div class="line">            std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line">        } <span class="keywordflow">else</span> {</div>
<div class="line">            std::vector&lt;size_t&gt; unsupported_op_ids = partitions[i].get_ops();</div>
<div class="line">            assertm(unsupported_op_ids.size() == 1, <span class="stringliteral">&quot;Unsupported partition only &quot;</span></div>
<div class="line">                <span class="stringliteral">&quot;contains single op.&quot;</span>);</div>
<div class="line">            <span class="keywordflow">if</span> (op_id_kind_map[unsupported_op_ids[0]] == op::kind::Wildcard) {</div>
<div class="line">                std::cout &lt;&lt; <span class="stringliteral">&quot;\nWarning (actually an error): partition &quot;</span> &lt;&lt; partitions[i].get_id() &lt;&lt;</div>
<div class="line">                        <span class="stringliteral">&quot; contains only a Wildcard op which cannot be computed.\n&quot;</span>;</div>
<div class="line">            } <span class="keywordflow">else</span> {</div>
<div class="line">                <span class="keywordflow">continue</span>;</div>
<div class="line">            }</div>
<div class="line">        }</div>
<div class="line">    }</div>
<div class="line">    </div>
<div class="line">    <span class="keywordtype">float</span> bn_scale = 1.0, bn_mean = 1.0, bn_shift = 1.0, bn_var = 1.0;</div>
<div class="line">    <span class="comment">// Step 6: Check correctness of the output results</span></div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Check correctness------------------------------&quot;</span>;</div>
<div class="line">    <span class="keywordtype">float</span> expected_result = bn_scale</div>
<div class="line">                    * ((bn_scale * ((1 * 1 * 1 * 256) - bn_mean)</div>
<div class="line">                                       / std::sqrt(bn_var)</div>
<div class="line">                               + bn_shift)</div>
<div class="line">                                    * (1 * 1 * 64)</div>
<div class="line">                            - bn_mean)</div>
<div class="line">                    / std::sqrt(bn_var)</div>
<div class="line">            + bn_shift + <span class="comment">/* residual connection */</span> 1;</div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> t_num=0; t_num &lt; thread_num; t_num++) {</div>
<div class="line">        <span class="keywordtype">float</span> *actual_output_ptr = tms[t_num].get(relu1_dst_desc.get_id()).get_data_handle&lt;float&gt;();</div>
<div class="line">        <span class="keyword">auto</span> output_dims = relu1_dst_desc.get_dims();</div>
<div class="line">        <span class="keyword">auto</span> num_elem = product(output_dims);</div>
<div class="line">        std::vector&lt;float&gt; expected_output(num_elem, expected_result);</div>
<div class="line">        compare_data(expected_output.data(), actual_output_ptr, num_elem);</div>
<div class="line">    }</div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;Success!\n&quot;</span>;</div>
<div class="line">    std::cout &lt;&lt; <span class="stringliteral">&quot;============Run Example Successfully===========\n&quot;</span>;</div>
<div class="line"> </div>
<div class="line">    <span class="keywordflow">return</span> 0;</div>
<div class="line">}</div>
<div class="line"><span class="comment">// clang-format on</span></div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1engine_html_a425168b38184f5d22b9eebfb3193b40e"><div class="ttname"><a href="classdnnl_1_1graph_1_1engine.html#a425168b38184f5d22b9eebfb3193b40e">dnnl::graph::engine::kind</a></div><div class="ttdeci">kind</div><div class="ttdoc">engine kind</div><div class="ttdef"><b>Definition:</b> dnnl_graph.hpp:102</div></div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1engine_html_a425168b38184f5d22b9eebfb3193b40ea0aa0be2a866411d9ff03515227454947"><div class="ttname"><a href="classdnnl_1_1graph_1_1engine.html#a425168b38184f5d22b9eebfb3193b40ea0aa0be2a866411d9ff03515227454947">dnnl::graph::engine::kind::gpu</a></div><div class="ttdeci">@ gpu</div><div class="ttdoc">GPU engine.</div></div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1logical__tensor_html_acddb1dc65b7b4feede7710a719f32227"><div class="ttname"><a href="classdnnl_1_1graph_1_1logical__tensor.html#acddb1dc65b7b4feede7710a719f32227">dnnl::graph::logical_tensor::data_type</a></div><div class="ttdeci">data_type</div><div class="ttdoc">Data Type.</div><div class="ttdef"><b>Definition:</b> dnnl_graph.hpp:302</div></div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1logical__tensor_html_ad3fcaff44671577e56adb03b770f4867"><div class="ttname"><a href="classdnnl_1_1graph_1_1logical__tensor.html#ad3fcaff44671577e56adb03b770f4867">dnnl::graph::logical_tensor::layout_type</a></div><div class="ttdeci">layout_type</div><div class="ttdoc">Layout type.</div><div class="ttdef"><b>Definition:</b> dnnl_graph.hpp:319</div></div>
<div class="ttc" id="aclassdnnl_1_1graph_1_1partition_html_a439c0490ea8ea85f2a12ec7b320a9a3ca051de32597041e41f73b97d61c67a13b"><div class="ttname"><a href="classdnnl_1_1graph_1_1partition.html#a439c0490ea8ea85f2a12ec7b320a9a3ca051de32597041e41f73b97d61c67a13b">dnnl::graph::partition::policy::fusion</a></div><div class="ttdeci">@ fusion</div><div class="ttdoc">Have fusion.</div></div>
</div><!-- fragment --> </div><!-- contents -->
</div><!-- doc-content -->
<div class="footer">
    <script>
        $('#top').prependTo($('#side-nav'));
    </script>
    <div class="footer-wrapper">
        <hr>
        <ul class="footer-links">
            <li><a href="legal_information.html">Legal information</a></li>
        </ul>
    </div>
</div>